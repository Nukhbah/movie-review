{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KaC0YLVlxjQ"
      },
      "source": [
        "# **Sentiment Analysis on IMDB Movie Reviews**\n",
        "\n",
        "The project involves preprocessing the text data, training a machine learning model, and evaluating its performance in classifying reviews as either positive or negative.\n",
        "\n",
        "---\n",
        "[Dataset](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) is sourced from kaggle\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfSAauhSmi_B"
      },
      "source": [
        "## **Loading Dataset**\n",
        "\n",
        "\n",
        "loading the dataset using `pandas` The dataset is stored in a CSV file located in the resources directory of the cloned repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSe1ZuiDtv-Q",
        "outputId": "fb7d3375-47bc-4d4d-e60c-3541480adfb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Loading the dataset\n",
        "data_path = 'movie-review/resources/IMDB Dataset.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HEYsuv1uPpN",
        "outputId": "b7cf05b9-0c49-4637-91d8-b990392fbc44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\n"
          ]
        }
      ],
      "source": [
        "print(data['review'].iloc[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysu93uOVnHez"
      },
      "source": [
        "## **Preprocessing**\n",
        "To prepare the text data for model training, following steps are performed:\n",
        "\n",
        "*   HTML Tags Removal\n",
        "*   URL and Mention Removal\n",
        "*   Tokenization\n",
        "*   Stop Words Removal (removing common words)\n",
        "*   Stemming (to reduce words to their base form)\n",
        "*   Conversion to Lowercase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oPPHQn3Buaid"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aCSeJTOZworM"
      },
      "outputs": [],
      "source": [
        "def tokenizer(text):\n",
        "    '''\n",
        "    Removes HTML tags, URLs, mentions, hashtags, and special characters.\n",
        "    Tokenizes the cleaned text into words.\n",
        "    '''\n",
        "    text = re.sub('<br />', '', text)\n",
        "    text = re.sub(r\"https\\S+|www\\S+|http\\S+\", '', text, flags = re.MULTILINE)\n",
        "    text = re.sub(r'\\@w+|\\#', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text_tokens = word_tokenize(text)\n",
        "    return text_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P60x4l4GZAtl",
        "outputId": "2904d7b0-1364-49b9-8040-eb66d3260a8f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\nukhb\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\nukhb\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\nukhb\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdiUsS71ugeK",
        "outputId": "817b6f17-1e45-4065-d3c8-3f865684f4b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              review sentiment  \\\n",
            "0  One of the other reviewers has mentioned that ...  positive   \n",
            "1  A wonderful little production. <br /><br />The...  positive   \n",
            "2  I thought this was a wonderful way to spend ti...  positive   \n",
            "3  Basically there's a family where a little boy ...  negative   \n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
            "\n",
            "                                    processed_review  \n",
            "0  one review mention watch 1 oz episod youll hoo...  \n",
            "1  a wonder littl product the film techniqu unass...  \n",
            "2  i thought wonder way spend time hot summer wee...  \n",
            "3  basic there famili littl boy jake think there ...  \n",
            "4  petter mattei love time money visual stun film...  \n"
          ]
        }
      ],
      "source": [
        "def preprocess_text(text):\n",
        "    '''\n",
        "    Preprocesses the input text by tokenizing, removing stop words,\n",
        "    Stemming, and converting to lowercase.\n",
        "    '''\n",
        "    tokens = tokenizer(text)                          # Tokenization\n",
        "    tokens = [word for word in tokens if word.isalnum()]  # Stop words removal\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]       # Stemming\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "data['processed_review'] = data['review'].apply(preprocess_text)\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwaIG_iZvslg",
        "outputId": "4a951de0-06da-4f53-c711-11354d61c8e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a wonder littl product the film techniqu unassum oldtimebbc fashion give comfort sometim discomfort sens realism entir piec the actor extrem well chosen michael sheen got polari voic pat you truli see seamless edit guid refer william diari entri well worth watch terrificli written perform piec a master product one great master comedi life the realism realli come home littl thing fantasi guard rather use tradit dream techniqu remain solid disappear it play knowledg sens particularli scene concern orton halliwel set particularli flat halliwel mural decor everi surfac terribl well done\n",
            "positive\n"
          ]
        }
      ],
      "source": [
        "print(data['processed_review'].iloc[1])\n",
        "print(data['sentiment'].iloc[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC0MbzPVnw_o"
      },
      "source": [
        "## **Model Training and evaluation**\n",
        "\n",
        "The dataset is split into training and test sets, with 80% of the data used for training and 20% for testing. The text data is vectorized using `TF-IDF` to transform it into a numerical format suitable for model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ty72xu2qNmhq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hO_JitwaMrqU"
      },
      "outputs": [],
      "source": [
        "X = data['processed_review']\n",
        "y = data['sentiment']\n",
        "\n",
        "# Splitting the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LIpjKA-iN1WG"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZCtWvpcoBXD"
      },
      "source": [
        "first training the Naive bayes model and seeing its performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZXe456TN4lT",
        "outputId": "69c627dd-8643-4070-8f05-115e0793a6df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Model\n",
            "Accuracy: 0.8637\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.88      0.86      4961\n",
            "    positive       0.88      0.85      0.86      5039\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_nb = nb_model.predict(X_test_vectorized)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Naive Bayes Model\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioziF60ToKJg"
      },
      "source": [
        "Now, evaluating the performance of logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVngatpHN9g5",
        "outputId": "eb5c2c49-0c23-4ff4-9488-c4dfd3d0095b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Model\n",
            "Accuracy: 0.8904\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.90      0.87      0.89      4961\n",
            "    positive       0.88      0.91      0.89      5039\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_lr = lr_model.predict(X_test_vectorized)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Logistic Regression Model\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aoENiNqoP0V"
      },
      "source": [
        "## **Predicting Sentiment for Sample Reviews**\n",
        "\n",
        "As logistic regression has acheived more accuracy than naive bayes I am choosing logistic regression to predict sample reviews and comparing them to actual sentiments to see how well model actually is predicting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS3oh4T2lhQF",
        "outputId": "2311a719-4b38-45c1-ef9e-6d8828b988a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review 1:\n",
            "Text: tortuou emot impact degrad whether adult adolesc person valu shown movi belong bad psychodrama anywher thi movi plot evil start end thi way peopl act degrad sex way movi teen kill bad preteen sex bad emot batter bad anim cruelti bad psycholog tortur bad parent neglect bad merit excel color shot contrast red blond green leav bad feel anyon respect life peac bad mistak make watch ugli\n",
            "Predicted Sentiment: negative\n",
            "Actual Sentiment: negative\n",
            "--------------------------------------------------------------------------------\n",
            "Review 2:\n",
            "Text: anyon know anyth evolut wouldnt even need see film say fake never disprov also weak argument say univers creat giant hippo disprov although fair seem like peopl believ peopl open email attach peopl dont know give bank detail dude zambia no bone primat found unit state canada there also good reason legitim scientist dont bother studi the argument goe loch ness monster ghost god\n",
            "Predicted Sentiment: negative\n",
            "Actual Sentiment: negative\n",
            "--------------------------------------------------------------------------------\n",
            "Review 3:\n",
            "Text: im glad i rent movi one reason shortcom made want read allend book get full stori pro movi beauti period depict well consist best knowledg meryl glenn good jobscon thi worst act job ive ever seen jeremi ironsi kept wonder someth wrong mouth and i hate terribl english way say transito winona ryder noth believ except look young idealist most perform ok thing hang togeth charact arc relationship develop i frustrat angri well end im curiou whether movi typic bill august work i may drop anoth coupl buck rent smilla sens snow\n",
            "Predicted Sentiment: negative\n",
            "Actual Sentiment: negative\n",
            "--------------------------------------------------------------------------------\n",
            "Review 4:\n",
            "Text: ye vote thi film may well plan 9 from outer space gener but wherea ed wood film flaw retain certain charm despit film defin word charmless nth degre in fact id suggest editor oxford english dictionari cite movi key exampl defin word next updat dictionarycarrot top perform abysm abil normal ration peopl i know hear name becom homicid maniac dedic want kill mr top soon possibl inde one goe amazoncom look custom review carrot top movi perform dvd one find sever could constru death threat mr topon curiou fact film i recal mike nelson head writer mst 3000 book mike mega chees movi good bad said saw film shortli afterword couldnt recal thing includ titl obvious mike suffer classic reaction trauma view atroc soul numb mike nelson block mind evid later chapter book mike nelson recov memeori film from review offer mike nelson definit grate recov memoryth comment i offer film spoiler simpli god honest truth funni none even nanosecond funni\n",
            "Predicted Sentiment: positive\n",
            "Actual Sentiment: negative\n",
            "--------------------------------------------------------------------------------\n",
            "Review 5:\n",
            "Text: thi miniseri actual entertain other much bigger budget grander aspir sotd fall somewher kungfu h r pufnstuff entertain spectrum if werent long nearli 3 hour i think kid would like quit bit it got adventur action cliffhang scene much romanc icki stuff when your young your critic flex rubber sword campi act scene repeat at least two scene repeat ident movi done oldtim serial order bring audienc speed final kid usual accept american english dialogu come mouth asian actor not mention fact sever lead role play nonasian actor i go give movi three star i felt like director produc cast deserv extra credit least carri project thi movi art like paint hous actual took time effort disciplin get madeoveral recommend use time might keep kid entertain travel minivanoh yeahhey imdb dialogu prefer tradit spell your spellcheck seem think dialog proper spell while dialog accept webster o consid altern form\n",
            "Predicted Sentiment: negative\n",
            "Actual Sentiment: negative\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Select 5 random reviews from the test set\n",
        "sample_reviews = X_test.sample(5, random_state=42)\n",
        "\n",
        "# Predict sentiment using Logistic Regression model\n",
        "predicted_sentiments = lr_model.predict(vectorizer.transform(sample_reviews))\n",
        "\n",
        "# Actual sentiments for comparison\n",
        "actual_sentiments = y_test[sample_reviews.index]\n",
        "\n",
        "for i, review in enumerate(sample_reviews):\n",
        "    print(f\"Review {i+1}:\")\n",
        "    print(f\"Text: {review}\")\n",
        "    print(f\"Predicted Sentiment: {predicted_sentiments[i]}\")\n",
        "    print(f\"Actual Sentiment: {actual_sentiments.iloc[i]}\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "saving the preprocessed data file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.to_csv('preprocessed_IMDB_dataset.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
